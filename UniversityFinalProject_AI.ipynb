{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmetemincopur/ImageProcessing_UniversityFinalProject/blob/main/UniversityFinalProject_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDt8kjZxX_Oq",
        "outputId": "c82513f3-f30f-4595-d764-e2e56f329995"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/Colab Notebooks/4.2.Dönem-Bitirme Projesi\n",
            "angles2.csv  binary-model1.h5                      \u001b[0m\u001b[01;34mmodeller\u001b[0m/\n",
            "angles3.csv  BitirmeProje.ipynb                    test2.csv\n",
            "angles.csv   BitirmeProjesiModellerleTahmin.ipynb  test.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%cd gdrive/My Drive/Colab Notebooks/4.2.Dönem-Bitirme Projesi\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WWqjGMcxYNeQ"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "\n",
        "#numpy.random.seed(7)\n",
        "#dataset=numpy.loadtxt('angles2.csv' , delimiter='|')\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('angles.csv', delimiter='|')\n",
        "dataset = data.iloc[:, 0:12].values\n",
        "\n",
        "datalar=dataset[:,0:11]\n",
        "etiketler=dataset[:,11]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8JZ4zhnzoP3M"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Veri setini eğitim ve test setlerine ayır\n",
        "train_datalar, test_data, train_etiketler, test_etiketler = train_test_split(datalar, etiketler, test_size=0.1, random_state=42)\n",
        "\n",
        "# Eğitim setini eğitim ve doğrulama setlerine ayır\n",
        "train_data, validation_data, train_etiketler, validation_etiketler = train_test_split(train_datalar, train_etiketler, test_size=0.111, random_state=42)\n",
        "\n",
        "train_etiketler = train_etiketler.astype('int32')\n",
        "validation_etiketler = validation_etiketler.astype('int32')\n",
        "test_etiketler = test_etiketler.astype('int32')\n",
        "\n",
        "print(train_data[0])\n",
        "\n",
        "train_datalar=train_data[:,1:11]\n",
        "test_datalar=test_data[:,1:11]\n",
        "validation_datalar=validation_data[:,1:11]\n",
        "\n",
        "print(train_datalar[0])\n",
        "\n",
        "train_datalar = tf.convert_to_tensor(train_datalar, dtype=tf.float32)\n",
        "test_datalar = tf.convert_to_tensor(test_datalar, dtype=tf.float32)\n",
        "validation_datalar = tf.convert_to_tensor(validation_datalar, dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUcPTQcbYogo"
      },
      "outputs": [],
      "source": [
        "model=Sequential()\n",
        "model.add(Dense(256, activation='relu', input_dim=10))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6KemPesYqZp",
        "outputId": "1cc69050-1455-447c-94a5-17c167dfc9b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "237/237 [==============================] - 1s 3ms/step - loss: 16.1792 - accuracy: 0.3030\n",
            "\n",
            " accuracy : 30.30%\n",
            "------------------------------------------------------\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 16.1792 - accuracy: 0.3030\n",
            "\n",
            " loss : 1617.92%\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "basarim=model.evaluate(train_datalar, train_etiketler)\n",
        "print(\"\\n %s : %.2f%%\" % (model.metrics_names[1], basarim[1]*100))\n",
        "print(\"------------------------------------------------------\")\n",
        "basarim=model.evaluate(train_datalar, train_etiketler)\n",
        "print(\"\\n %s : %.2f%%\" % (model.metrics_names[0], basarim[0]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9QWYUCQ-RO0w"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "best_models_info = []\n",
        "\n",
        "# Gizli katmanların farklı konfigürasyonlarını tanımla\n",
        "hidden_layer_configs = [\n",
        "    [128, layer3_units] for layer3_units in range(1, 64)\n",
        "]\n",
        "\n",
        "best_val_accuracy = 0\n",
        "best_val_loss = float('inf')\n",
        "best_train_accuracy = 0\n",
        "best_train_loss = float('inf')\n",
        "best_model = None\n",
        "best_hidden_layers = []\n",
        "\n",
        "for hidden_layers in hidden_layer_configs:\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.InputLayer(input_shape=10))\n",
        "    for num_units in hidden_layers:\n",
        "        model.add(keras.layers.Dense(num_units, activation='relu'))\n",
        "    model.add(keras.layers.Dense(3, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    history = model.fit(train_datalar, train_etiketler, epochs=10, batch_size=32, validation_data=(validation_datalar, validation_etiketler))\n",
        "    val_accuracy = history.history['val_accuracy'][-1]\n",
        "    val_loss = history.history['val_loss'][-1]\n",
        "\n",
        "    train_accuracy = history.history['accuracy'][-1]\n",
        "    train_loss = history.history['loss'][-1]\n",
        "\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = val_accuracy\n",
        "        best_val_loss = val_loss\n",
        "        best_train_accuracy = train_accuracy\n",
        "        best_train_loss = train_loss\n",
        "        best_model = model\n",
        "        best_hidden_layers = hidden_layers\n",
        "\n",
        "    # Her modelin ayrıntılarını sakla\n",
        "    model_info = {\n",
        "        'hidden_layers': hidden_layers,\n",
        "        'val_accuracy': val_accuracy,\n",
        "        'val_loss': val_loss,\n",
        "        'train_accuracy': train_accuracy,\n",
        "        'train_loss': train_loss\n",
        "    }\n",
        "    best_models_info.append(model_info)\n",
        "\n",
        "# En iyi modelin ayrıntılarını yazdır\n",
        "print(\"Best Model Architecture:\")\n",
        "print(best_model.summary())\n",
        "print(\"Best Model Hyperparameters:\")\n",
        "print(\"Hidden Layers:\", best_hidden_layers)\n",
        "print(\"Validation Accuracy:\", best_val_accuracy)\n",
        "print(\"Validation Loss:\", best_val_loss)\n",
        "print(\"Train Accuracy:\", best_train_accuracy)\n",
        "print(\"Train Loss:\", best_train_loss)\n",
        "\n",
        "# Bütün modellerin ayrıntılarını yazdır\n",
        "print(\"\\nDetails of All Models:\")\n",
        "for model_info in best_models_info:\n",
        "    print(\"\\nHidden Layers:\", model_info['hidden_layers'])\n",
        "    print(\"Validation Accuracy:\", model_info['val_accuracy'])\n",
        "    print(\"Validation Loss:\", model_info['val_loss'])\n",
        "    print(\"Train Accuracy:\", model_info['train_accuracy'])\n",
        "    print(\"Train Loss:\", model_info['train_loss'])\n",
        "    print(\"--------------------------------------------------\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSZquLtfSPcP",
        "outputId": "4084722f-36ae-4fc4-da19-964853ba04f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<keras.engine.sequential.Sequential object at 0x77fd475ebca0>\n"
          ]
        }
      ],
      "source": [
        "print(best_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwEVuXfNYrvA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Modelin eğitim ve doğrulama kayıplarını ve doğruluk değerlerini elde et\n",
        "history = model.fit(train_datalar, train_etiketler, epochs=100, batch_size=32, validation_data=(validation_datalar, validation_etiketler))\n",
        "\n",
        "# Eğitim ve doğrulama kaybı değerlerini al\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Eğitim ve doğrulama doğruluk değerlerini al\n",
        "train_acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "# Eğitim ve doğrulama kayıp değerlerinin grafiğini çiz\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, len(train_loss) + 1), train_loss, label='Eğitim Kaybı')\n",
        "plt.plot(range(1, len(val_loss) + 1), val_loss, label='Doğrulama Kaybı')\n",
        "plt.title('Eğitim ve Doğrulama Kaybı')\n",
        "plt.xlabel('Epok')\n",
        "plt.ylabel('Kayıp')\n",
        "plt.legend()\n",
        "\n",
        "# Eğitim ve doğrulama doğruluk değerlerinin grafiğini çiz\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, len(train_acc) + 1), train_acc, label='Eğitim Doğruluğu')\n",
        "plt.plot(range(1, len(val_acc) + 1), val_acc, label='Doğrulama Doğruluğu')\n",
        "plt.title('Eğitim ve Doğrulama Doğruluğu')\n",
        "plt.xlabel('Epok')\n",
        "plt.ylabel('Doğruluk')\n",
        "plt.legend()\n",
        "\n",
        "# Grafikleri göster\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VPBTEv-Ytox"
      },
      "outputs": [],
      "source": [
        "basarim=model.evaluate(train_datalar, train_etiketler)\n",
        "print(\"\\n %s : %.2f%%\" % (model.metrics_names[1], basarim[1]*100))\n",
        "print(\"------------------------------------------------------\")\n",
        "basarim=model.evaluate(train_datalar, train_etiketler)\n",
        "print(\"\\n %s : %.2f%%\" % (model.metrics_names[0], basarim[0]*100))\n",
        "\n",
        "print(\"##########################################################\")\n",
        "basarim=model.evaluate(validation_datalar, validation_etiketler)\n",
        "print(\"\\n %s : %.2f%%\" % (model.metrics_names[1], basarim[1]*100))\n",
        "print(\"------------------------------------------------------\")\n",
        "basarim=model.evaluate(validation_datalar, validation_etiketler)\n",
        "print(\"\\n %s : %.2f%%\" % (model.metrics_names[0], basarim[0]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0gDARvcYw-R"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIGXtL66kr87"
      },
      "outputs": [],
      "source": [
        "# Tahminleri yap\n",
        "y_pred = model.predict(test_datalar)\n",
        "\n",
        "# Tahminleri sınıflara dönüştür\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Gerçek etiketleri sınıflara dönüştür\n",
        "test_etiketler_classes = np.array(test_etiketler, dtype=int)\n",
        "\n",
        "# Tahminleri ve gerçek etiketleri karşılaştır ve doğruluğu hesapla\n",
        "dogruluk = np.mean(y_pred_classes == test_etiketler_classes)\n",
        "\n",
        "for i in range(len(test_etiketler)):\n",
        "    resim_adı = test_data[i, 0]  # Burada test_data'yı kullanarak resim adını alıyoruz\n",
        "    tahmin = y_pred_classes[i]\n",
        "    print(\"Resim Adı: %s, Tahmin: %d\" % (resim_adı, tahmin))\n",
        "\n",
        "# Sonucu yazdır\n",
        "print(\"Test Doğruluğu: %.2f%%\" % (dogruluk * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLBHPARIu_1l"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Confusion matrix'i hesapla\n",
        "cm = confusion_matrix(test_etiketler, y_pred_classes)\n",
        "\n",
        "# Doğru ve yanlış tahmin sayılarını elde et\n",
        "true_positive = cm[1, 1]  # Doğru pozitif\n",
        "true_negative = cm[0, 0]  # Doğru negatif\n",
        "false_positive = cm[0, 1]  # Yanlış pozitif\n",
        "false_negative = cm[1, 0]  # Yanlış negatif\n",
        "\n",
        "print(\"Doğru Pozitif: \", true_positive)\n",
        "print(\"Doğru Negatif: \", true_negative)\n",
        "print(\"Yanlış Pozitif: \", false_positive)\n",
        "print(\"Yanlış Negatif: \", false_negative)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8n0bYsblsn2j"
      },
      "outputs": [],
      "source": [
        "model.save(\"en-uygun-model2.h5\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOzlSfIIuADFj9MdNjTtmp",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}